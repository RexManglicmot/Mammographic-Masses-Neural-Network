---
title: "Mammographic Masses Neural Network"
author: "Rex Manglicmot"
date: "2023-01-01"
output: 
  github_document: 
    toc: yes
---

## Continuing Working Document

Things still need to do/questions:

* more info on neural networks
* flush out intro
* get feedback on project
* better visulization for the dataset?


## Introduction
<center>
![](https://mygenius3d.com/wp-content/uploads/2022/07/Hologic-Clarity-HD-1800x1013.jpg)

</center>
Breast Cancer is a disease that warrants much attention because according to the CDC, it is the most common cancer in women, with incidence rates increasing 0.5%/year, and roughly 13% will develop BC in their lifetime.^[https://www.cancer.org/cancer/breast-cancer/about/how-common-is-breast-cancer.html] According to Breastcancer.org, the overall breast cancer deaths have declined to 43% from 1989-2020 due to treatment advances and early detection.^[https://www.breastcancer.org/facts-statistics] Nevertheless, about 42K women and 500 men die per year.^[https://www.cdc.gov/cancer/breast/basic_info/index.htm#:~:text=Each%20year%20in%20the%20United,breast%20cancer%20than%20White%20women.] Therefore, there is a dire need for prevention and early detection.

The purpose of this project is to identify ways to predict BC through classification of numeric features. By doing this research we are extrapolate the model to identify women who fit the classification and propose steps to help decrease the likeliness of incidence. The model I will be using is Neural Networks.

This project is organized in the following chapters:

1. Loading the Libraries
2. Loading the Data
3. Cleaning the Data
4. Exploratory Data Analysis
5. Neural Networks
6. Limitations
7. Conclusion
8. Inspiration for this project

A special acknowledgement to the University of Irvine data repository for making the dataset open to the public. A further special acknowledgement to M. Elter, R. Schulz-Wendtland and T. Wittenberg for their paper and providing the dataset.^[M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007)
The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.
Medical Physics 34(11), pp. 4164-4172]

The original dataset contains the following variables:

1. BI-RADS assessment: 1 to 5 (ordinal, non-predictive!)
2. Age: patient's age in years (integer)
3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)
4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)
5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)
6. Severity: benign=0 or malignant=1 (binominal, goal field!)

## Loading the Libraries
```{r, message=FALSE}
library(tidyverse)
library(viridis)
library(neuralnet)
```


## Loading the Data
```{r}
#get data from UCI website
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data'

#load data into object
data_orig <- read.csv(url)
```


## Cleaning the Data
```{r}
# look at data
str(data_orig)
```
It would seem that the data is messy.

On the UCI website it listed that the there are a total of 961 observatins but we have only 960. Therefore, the column name would appear to be an observation. However, upo further inspection, the "X5.1" and "X3.1" column does not make any sense because values should be based on 1-5 and 1-4, respectively. I will therefore delete that observation from the dataset and relabel the columns. 

But first, I will make a copy of the original dataset for manipulation.

```{r}
#make a copy
data <- data_orig

#change column names
colnames(data) <- c('BIRAD', 'age', 'shape', 'margin', 'density', 'result')

#get rid of BIRAD since on the UCI website it is non-predictive
data <- subset(data, select = -(BIRAD))

#How many NA do we have?
sum(is.na(data))
  
#how many columns have ?
sum(data == '?')

# which specific observations have '?'
which(data == '?')

# which specific observations have '*'
sum(data == '*')

#Replace ? with NAs
data[data == '?'] <- NA

#sum the NAs again
sum(is.na(data))

#remove the NA observations
data <- na.omit(data)

#dimensions of the dataset
dim(data)
```

Let's change the class
```{r}
#convert age column into a numeric
data$age <- as.numeric(as.character(data$age))

#create a list to convert remaining columns
index <- 2:ncol(data)

#pass list to function
data[ ,index] <- lapply(data[ ,index], as.factor)

#check structure again
str(data)
```
## Exploratory Data Analysis
```{r}
#see the summary statistics
summary(data)
```
This is interesting. Here are some insights:

* the age of the dataset ranges from 18 to 96 with a mean of 57.
* shape variable has more of the 4 category than 1.
* margin variable has more of the 4 category than 1. 
* density varaible has much more of the 3 cateogry than the others.
* result variable seems to be about even.

```{r}
#create a histogram of the ages overall
ggplot(data, aes(x=age)) +
  geom_histogram() +
  theme_classic()
```

The shape of the distribution looks normal. Let's break it apart into result 0 and 1.

```{r}
#create a histogram of the ages for 0 and 1
ggplot(data, aes(x= age, fill= result)) +
  geom_histogram(position = 'dodge',
                 color = 'black') +
  theme_classic() #+
  # facet_wrap(~result) 

```

The distribution looks normal for both, but the means are obviously different. 

```{r}
#let's look at shape
ggplot(data, aes(x=age, y=shape, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

Interesting. There the ages we see that there is more of 0 in shape categories 1 and 2 while there is more1 in shape category 4. I might also add that there are few observations in shape category 3 for both 0 and 1. 


```{r}
#let's look at margin
ggplot(data, aes(x=age, y=margin, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

```{r}
#let's look at density
ggplot(data, aes(x=age, y=density, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

## Artificial Neural Networks
Artificial Neural Networks is akin to the nervous system in that the model uses several neurons through an interconnected pathway to detect hidden patterns in complex datasets. ANN take in data and train to recoginize patterns and predict outputs. 

Examples of ANN is facial recognition, forecasting, music composition, etc.

ANN comprised of:

- an **input layer**: receives the input 
- a **hidden layer(s)**: consist of neurons and is between the input and output layer and performs most of the computations.
- an **output layer**: predicts final output

![](https://miro.medium.com/max/828/1*x6KWjKTOBhUYL0MRX4M3oQ.webp)

On a much deeper level neurons consists of inputs, weights, bias, activation function, and output. 


```{r}
#convert the columns factors into an integer because factors can't be normalized
data2 <- as.data.frame(lapply(data,as.integer))

#check the class
lapply(data2, class)
```

```{r}
#normalize the dataset with a function
data_norm <- function (x) {
  ((x-min(x))/ (max(x)- min(x)))
}

#use lapply to normalize the data
data3 <- as.data.frame(lapply(data2, data_norm))

#check if all values are from 0 to 1
summary(data3)
```
```{r}
#make results reproducible
set.seed(123)

#split the data into an 80 and 20 split
sample <- sample(2, nrow(data3), replace= TRUE, 
                 prob= c(0.8, 0.2))

#train and test set
train <- data3[sample==1, ]
test <- data3[sample==2, ]
```

```{r}
#make results reproducible
set.seed(456)

#create a neural network from our train dataset
n <- neuralnet(result~., data= train,
               #1 layer for now 
               hidden = 1,
               err.fct = 'ce',
               linear.output = FALSE
               )

#plot the neural network
#need to add the "rep='best'" code, otherwise plot won't show up on Rmarkdown
plot(n, rep='best')
```

4 inputs layer with 4 nodes and 1 output layer with 1 node. There is 1 hidden layer (as specified in our code) or neuron.

```{r}
#Train data -- build confusion matrix
output <- compute(n, train[,-5])

#store net.result into output object and into another object
p1 <- output$net.result

#convert the probabilities into binary factor:
#1, if p1 > 0.5 or 0, if p1 < 0.5
pred1 <- ifelse(p1 > 0.5, 1, 0)

#build out confusion matrix into a table
table1 <- table(pred1, train$result)

#view table
print(table1)
```
Insights:

* 271 patients were correctly classified as 0
* 261 patients were correctly classified as 1

There are misclassifications. 
```{r}
#calculate missclassification error
1-sum(diag(table1))/sum(table1)

#Note: sum(diag(table1))/sum(table1) by itself, it gives accuracy.
```

Misclassification error is 20%.

Repeat for test data.
```{r}
#Test data -- build confusion matrix
output2 <- compute(n, test[,-5])

#store net.result into output object and into another object
p2 <- output2$net.result

#convert the probabilities into binary factor:
#1, if p1 > 0.5 or 0, if p1 < 0.5
pred2 <- ifelse(p2 > 0.5, 1, 0)

#build out confusion matrix into a table
table2 <- table(pred2, test$result)

#view table
print(table2)
```

Insights:

*  67 patients were correctly classified as 0
*  68 patients were correctly classified as 1

```{r}
#calculate misclassification error
1-sum(diag(table2))/sum(table2)
```

Misclassification error, again, is 20%.

Neural network is consistent with both the train and test datasets.

Let's try with more hidden layers.
```{r}
#let's arbitrarily try 4 due to number of inputs
#create a neural network from our train dataset
n2 <- neuralnet(result~., data= train,
               #4 layer for now 
               hidden = 4,
               err.fct = 'ce',
               linear.output = FALSE
               )

#plot the neural network
plot(n2, rep='best')
```

## Limitations


## Conclusion


## Inspiration for this project
Inspiration for this project is history of breast cancer within my family. 