---
title: "Mammographic Masses Neural Network"
author: "Rex Manglicmot"
date: "2023-01-01"
output: 
  github_document: 
    toc: yes
---

## Continuing Working Document

## Introduction


## Loading the Libraries
```{r, message=FALSE}
library(tidyverse)
library(viridis)
library(neuralnet)
```


## Loading the Data
```{r}
#get data from UCI website
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data'

#load data into object
data_orig <- read.csv(url)
```


## Cleaning the Data
```{r}
# look at data
str(data_orig)
```
It would seem that the data is messy.

On the UCI website it listed that the there are a total of 961 observatins but we have only 960. Therefore, the column name would appear to be an observation. However, upo further inspection, the "X5.1" and "X3.1" column does not make any sense because values should be based on 1-5 and 1-4, respectively. I will therefore delete that observation from the dataset and relabel the columns. 

But first, I will make a copy of the original dataset for manipulation.

```{r}
#make a copy
data <- data_orig

#change column names
colnames(data) <- c('BIRAD', 'age', 'shape', 'margin', 'density', 'result')

#get rid of BIRAD since on the UCI website it is non-predictive
data <- subset(data, select = -(BIRAD))

#How many NA do we have?
sum(is.na(data))
  
#how many columns have ?
sum(data == '?')

# which specific observations have '?'
which(data == '?')

# which specific observations have '*'
sum(data == '*')

#Replace ? with NAs
data[data == '?'] <- NA

#sum the NAs again
sum(is.na(data))

#remove the NA observations
data <- na.omit(data)

#dimensions of the dataset
dim(data)
```

Let's change the class
```{r}
#convert age column into a numeric
data$age <- as.numeric(as.character(data$age))

#create a list to convert remaining columns
index <- 2:ncol(data)

#pass list to function
data[ ,index] <- lapply(data[ ,index], as.factor)

#check structure again
str(data)
```
## Exploratory Data Analysis
```{r}
#see the summary statistics
summary(data)
```
```{r}
#create a histogram of the ages overall
ggplot(data, aes(x=age)) +
  geom_histogram() +
  theme_classic()

#create a histogram of the ages for 0 and 1
ggplot(data, aes(x= age, fill= result)) +
  geom_histogram(position = 'dodge',
                 color = 'black') +
  theme_classic() #+
  # facet_wrap(~result) 

```
The distribution looks normal for both, but the means are obviously different. 

```{r}
#let's look at shape
ggplot(data, aes(x=age, y=shape, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```
Interesting.


```{r}
#let's look at margin
ggplot(data, aes(x=age, y=margin, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

```{r}
#let's look at density
ggplot(data, aes(x=age, y=density, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

## Neural Networks

```{r}
#convert the columns factors into an integer because factors can't be normalized
data2 <- as.data.frame(lapply(data,as.integer))

#check the class
lapply(data2, class)
```

```{r}
#normalize the dataset with a function
data_norm <- function (x) {
  ((x-min(x))/ (max(x)- min(x)))
}

#use lapply to normalize the data
data3 <- as.data.frame(lapply(data2, data_norm))

#check if all values are from 0 to 1
summary(data3)
```
```{r}
#make results reproducible
set.seed(123)

#split the data into an 80 and 20 split
sample <- sample(2, nrow(data3), replace= TRUE, 
                 prob= c(0.8, 0.2))

#train and test set
train <- data3[sample==1, ]
test <- data3[sample==2, ]
```

```{r}
#make results reproducible
set.seed(456)

#create a neural network from our train dataset
n <- neuralnet(result~., data= train,
               #1 layer for now 
               hidden = 1,
               err.fct = 'ce',
               linear.output = FALSE
               )

#plot the neural network
#need to add the "rep='best'" code, otherwise plot won't show up on Rmarkdown
plot(n, rep='best')
```

4 inputs layer with 4 nodes and 1 output layer with 1 node. There is 1 hidden layer (as specified in our code) or neuron.



## Limitations


## Conclusion


## Inspiration for this project