---
title: "Mammographic Masses Neural Network"
author: "Rex Manglicmot"
date: "2023-01-01"
output: 
  github_document: 
    toc: yes
---

## Continuing Working Document

## Introduction


## Loading the Libraries
```{r, message=FALSE}
library(tidyverse)
library(viridis)
library(neuralnet)
```


## Loading the Data
```{r}
#get data from UCI website
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data'

#load data into object
data_orig <- read.csv(url)
```


## Cleaning the Data
```{r}
# look at data
str(data_orig)
```
It would seem that the data is messy.

On the UCI website it listed that the there are a total of 961 observatins but we have only 960. Therefore, the column name would appear to be an observation. However, upo further inspection, the "X5.1" and "X3.1" column does not make any sense because values should be based on 1-5 and 1-4, respectively. I will therefore delete that observation from the dataset and relabel the columns. 

But first, I will make a copy of the original dataset for manipulation.

```{r}
#make a copy
data <- data_orig

#change column names
colnames(data) <- c('BIRAD', 'age', 'shape', 'margin', 'density', 'result')

#get rid of BIRAD since on the UCI website it is non-predictive
data <- subset(data, select = -(BIRAD))

#How many NA do we have?
sum(is.na(data))
  
#how many columns have ?
sum(data == '?')

# which specific observations have '?'
which(data == '?')

# which specific observations have '*'
sum(data == '*')

#Replace ? with NAs
data[data == '?'] <- NA

#sum the NAs again
sum(is.na(data))

#remove the NA observations
data <- na.omit(data)

#dimensions of the dataset
dim(data)
```

Let's change the class
```{r}
#convert age column into a numeric
data$age <- as.numeric(as.character(data$age))

#create a list to convert remaining columns
index <- 2:ncol(data)

#pass list to function
data[ ,index] <- lapply(data[ ,index], as.factor)

#check structure again
str(data)
```
## Exploratory Data Analysis
```{r}
#see the summary statistics
summary(data)
```
```{r}
#create a histogram of the ages overall
ggplot(data, aes(x=age)) +
  geom_histogram() +
  theme_classic()

#create a histogram of the ages for 0 and 1
ggplot(data, aes(x= age, fill= result)) +
  geom_histogram(position = 'dodge',
                 color = 'black') +
  theme_classic() #+
  # facet_wrap(~result) 

```
The distribution looks normal for both, but the means are obviously different. 

```{r}
#let's look at shape
ggplot(data, aes(x=age, y=shape, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```
Interesting.


```{r}
#let's look at margin
ggplot(data, aes(x=age, y=margin, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

```{r}
#let's look at density
ggplot(data, aes(x=age, y=density, color=result)) +
  geom_point(position = 'jitter', alpha = 0.5) +
  theme_classic()
```

## Artificial Neural Networks
Artificial Neural Networks is akin to the nervous system in that the model uses several neurons through an interconnected pathway to detect hidden patterns in complex datasets. ANN take in data and train to recoginize patterns and predict outputs. 

Examples of ANN is facial recognition, forecasting, music composition, etc.

ANN comprised of:

- an **input layer**: receives the input 
- a **hidden layer(s)**: consist of neurons and is between the input and output layer and performs most of the computations.
- an **output layer**: predicts final output

![](https://miro.medium.com/max/828/1*x6KWjKTOBhUYL0MRX4M3oQ.webp)

On a much deeper level neurons consists of inputs, weights, bias, activation function, and output. 


```{r}
#convert the columns factors into an integer because factors can't be normalized
data2 <- as.data.frame(lapply(data,as.integer))

#check the class
lapply(data2, class)
```

```{r}
#normalize the dataset with a function
data_norm <- function (x) {
  ((x-min(x))/ (max(x)- min(x)))
}

#use lapply to normalize the data
data3 <- as.data.frame(lapply(data2, data_norm))

#check if all values are from 0 to 1
summary(data3)
```
```{r}
#make results reproducible
set.seed(123)

#split the data into an 80 and 20 split
sample <- sample(2, nrow(data3), replace= TRUE, 
                 prob= c(0.8, 0.2))

#train and test set
train <- data3[sample==1, ]
test <- data3[sample==2, ]
```

```{r}
#make results reproducible
set.seed(456)

#create a neural network from our train dataset
n <- neuralnet(result~., data= train,
               #1 layer for now 
               hidden = 1,
               err.fct = 'ce',
               linear.output = FALSE
               )

#plot the neural network
#need to add the "rep='best'" code, otherwise plot won't show up on Rmarkdown
plot(n, rep='best')
```

4 inputs layer with 4 nodes and 1 output layer with 1 node. There is 1 hidden layer (as specified in our code) or neuron.

```{r}
#Train data -- build confusion matrix
output <- compute(n, train[,-5])

#store net.result into output object and into another object
p1 <- output$net.result

#convert the probabilities into binary factor:
#1, if p1 > 0.5 or 0, if p1 < 0.5
pred1 <- ifelse(p1 > 0.5, 1, 0)

#build out confusion matrix into a table
table1 <- table(pred1, train$result)

#view table
print(table1)
```
Insights:

* 271 patients were correctly classified as 0
* 261 patients were correctly classified as 1

There are misclassifications. 
```{r}
#calculate missclassification error
1-sum(diag(table1))/sum(table1)

#Note: sum(diag(table1))/sum(table1) by itself, it gives accuracy.
```

Misclassification error is 20%.

Repeat for test data.
```{r}
#Test data -- build confusion matrix
output2 <- compute(n, test[,-5])

#store net.result into output object and into another object
p2 <- output2$net.result

#convert the probabilities into binary factor:
#1, if p1 > 0.5 or 0, if p1 < 0.5
pred2 <- ifelse(p2 > 0.5, 1, 0)

#build out confusion matrix into a table
table2 <- table(pred2, test$result)

#view table
print(table2)
```

Insights:

*  67 patients were correctly classified as 0
*  68 patients were correctly classified as 1

```{r}
#calculate misclassification error
1-sum(diag(table2))/sum(table2)
```

Misclassification error, again, is 20%.

Neural network is consistent with both the train and test datasets.

Let's try with more hidden layers.
```{r}
#let's arbitrarily try 4 due to number of inputs
#create a neural network from our train dataset
n2 <- neuralnet(result~., data= train,
               #4 layer for now 
               hidden = 4,
               err.fct = 'ce',
               linear.output = FALSE
               )

#plot the neural network
plot(n2, rep='best')
```

## Limitations


## Conclusion


## Inspiration for this project